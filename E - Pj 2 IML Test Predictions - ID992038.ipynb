{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "trainFeatures = pd.read_csv(open(\"train_features.tsv\", encoding=\"utf8\"), sep = '\\t')\n",
    "trainLabels = pd.read_csv(open(\"train_labels.tsv\", encoding=\"utf8\"), sep = '\\t')\n",
    "testFeatures = pd.read_csv(open(\"test_features.tsv\", encoding=\"utf8\"), sep = '\\t')\n",
    "\n",
    "trainFeat = deepcopy(trainFeatures)\n",
    "trainLab = deepcopy(trainLabels)\n",
    "testFeat = deepcopy(testFeatures)\n",
    "\n",
    "trainSet = trainFeat.merge(trainLab, on='movieId', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6586: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "trainSet1 = trainSet.dropna(how = 'any')\n",
    "trainSet1.reset_index(drop = True, inplace = True)\n",
    "trainSet1['year'].replace(to_replace = '2010) ', value = '2010', inplace = True)\n",
    "trainSet1['year'].replace(to_replace = '2005) ', value = '2005', inplace = True)\n",
    "trainSet1['year'].replace(to_replace = '2013) ', value = '2013', inplace = True)\n",
    "trainSet1['year'].replace(to_replace = '2011) ', value = '2011', inplace = True)\n",
    "trainSet1['year'].replace(to_replace = '2012) ', value = '2012', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 - Vectorize words using Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#train features - tags\n",
    "\n",
    "newTagTrain = []\n",
    "\n",
    "for i in range(0, 5237):\n",
    "    tag = re.sub('[^a-zA-Z]', ' ', trainSet1['tag'][i])\n",
    "    tag = tag.lower()\n",
    "    tag = tag.split()\n",
    "    ps = PorterStemmer()\n",
    "    tag = [ps.stem(word) for word in tag if not word in set(stopwords.words('english'))]\n",
    "    tag = ' '.join(tag)\n",
    "    newTagTrain.append(tag)\n",
    "    \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer(max_features = 1500)\n",
    "tagTrainMatrix = cv.fit_transform(newTagTrain).toarray()\n",
    "tagTrainDf = pd.DataFrame(tagTrainMatrix)\n",
    "tagTrainDf.columns = cv.get_feature_names()\n",
    "\n",
    "tagTrainDf = tagTrainDf.rename(columns = lambda x: x + \"_ta\")\n",
    "\n",
    "#train features - titles\n",
    "\n",
    "newTitleTrain = []\n",
    "\n",
    "for i in range(0, 5237):\n",
    "    title = re.sub('[^a-zA-Z]', ' ', trainSet1['title'][i])\n",
    "    title = title.lower()\n",
    "    title = title.split()\n",
    "    ps = PorterStemmer()\n",
    "    title = [ps.stem(word) for word in title if not word in set(stopwords.words('english'))]\n",
    "    title = ' '.join(title)\n",
    "    newTitleTrain.append(title)\n",
    "    \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer(max_features = 1500)\n",
    "titleTrainMatrix = cv.fit_transform(newTitleTrain).toarray()\n",
    "titleTrainDf = pd.DataFrame(titleTrainMatrix)\n",
    "titleTrainDf.columns = cv.get_feature_names()\n",
    "\n",
    "titleTrainDf = titleTrainDf.rename(columns = lambda x: x + \"_ti\")\n",
    "\n",
    "#test features - tags\n",
    "\n",
    "newTagTest = []\n",
    "\n",
    "for i in range(0, 235):\n",
    "    tag = re.sub('[^a-zA-Z]', ' ', testFeat['tag'][i])\n",
    "    tag = tag.lower()\n",
    "    tag = tag.split()\n",
    "    ps = PorterStemmer()\n",
    "    tag = [ps.stem(word) for word in tag if not word in set(stopwords.words('english'))]\n",
    "    tag = ' '.join(tag)\n",
    "    newTagTest.append(tag)\n",
    "    \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer(max_features = 1500)\n",
    "tagTestMatrix = cv.fit_transform(newTagTest).toarray()\n",
    "tagTestDf = pd.DataFrame(tagTestMatrix)\n",
    "tagTestDf.columns = cv.get_feature_names()\n",
    "\n",
    "tagTestDf = tagTestDf.rename(columns = lambda x: x + \"_ta\")\n",
    "\n",
    "#test features - titles\n",
    "\n",
    "newTitleTest = []\n",
    "\n",
    "for i in range(0, 235):\n",
    "    title = re.sub('[^a-zA-Z]', ' ', testFeat['title'][i])\n",
    "    title = title.lower()\n",
    "    title = title.split()\n",
    "    ps = PorterStemmer()\n",
    "    title = [ps.stem(word) for word in title if not word in set(stopwords.words('english'))]\n",
    "    title = ' '.join(title)\n",
    "    newTitleTest.append(title)\n",
    "    \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer(max_features = 1500)\n",
    "titleTestMatrix = cv.fit_transform(newTitleTest).toarray()\n",
    "titleTestDf = pd.DataFrame(titleTestMatrix)\n",
    "titleTestDf.columns = cv.get_feature_names()\n",
    "\n",
    "titleTestDf = titleTestDf.rename(columns = lambda x: x + \"_ti\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 One hot encoder for years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearTr = trainSet1['year']\n",
    "yearAuxTr = pd.DataFrame(yearTr)\n",
    "yearsTrain = pd.get_dummies(yearAuxTr, drop_first = True)\n",
    "\n",
    "yearTe = testFeat['year']\n",
    "yearAuxTe = pd.DataFrame(yearTe)\n",
    "yearAuxTe = yearAuxTe.astype(str)\n",
    "yearsTest = pd.get_dummies(yearAuxTe, drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 - Scale data and match columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns movieId - YTId - title - tag - year\n",
    "trainSet2 = deepcopy(trainSet1)\n",
    "trainSet2.drop(columns = ['movieId', 'title', 'YTId', 'tag', 'year'], axis = 1, inplace = True)\n",
    "\n",
    "testFeat1 = deepcopy(testFeat)\n",
    "testFeat1.drop(columns = ['movieId', 'title', 'YTId', 'tag', 'year'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensions\n",
    "y_train = trainSet2.iloc[:, 127].values\n",
    "XAuxTrain = trainSet2.iloc[:, 0:127]\n",
    "\n",
    "# check dimensions\n",
    "XAuxTest = testFeat1.iloc[:, 0:127]\n",
    "\n",
    "# Feature Scaling - we use tfidf raw features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "XAuxTrain_yearsTrain = pd.concat([XAuxTrain, yearsTrain], axis = 1)\n",
    "XAuxTest_yearsTest = pd.concat([XAuxTest, yearsTest], axis = 1)\n",
    "XAuxTrain_yearsTrain1, XAuxTest_yearsTest1 = XAuxTrain_yearsTrain.align(XAuxTest_yearsTest, join = 'outer', axis = 1, fill_value = 0)\n",
    "\n",
    "XAuxTrain_yearsTrain_Sc = pd.DataFrame(ss.fit_transform(XAuxTrain_yearsTrain1),columns = XAuxTrain_yearsTrain1.columns)\n",
    "XAuxTest_yearsTest_Sc = pd.DataFrame(ss.transform(XAuxTest_yearsTest1),columns = XAuxTest_yearsTest1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([XAuxTrain_yearsTrain_Sc, tagTrainDf, titleTrainDf], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.concat([XAuxTest_yearsTest_Sc, tagTestDf, titleTestDf], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1 = X_train.align(X_test, join = 'outer', axis = 1, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the values\n",
    "X_train2 = deepcopy(X_train1)\n",
    "X_test2 = deepcopy(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Feature selection (All features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Specs       Score\n",
      "2019          war_ta  118.662076\n",
      "1361         noir_ta   80.839123\n",
      "526   documentari_ta   73.705935\n",
      "649            fi_ta   60.914879\n",
      "1705          sci_ta   60.914879\n",
      "67           anim_ta   54.865338\n",
      "916            ii_ta   48.883634\n",
      "2080        world_ta   48.883634\n",
      "43          alien_ta   42.873215\n",
      "1308        music_ta   42.627156\n",
      "190             avf7   38.646457\n",
      "629       fantasi_ta   38.443335\n",
      "1502        polit_ta   33.574243\n",
      "150            avf33   33.176945\n",
      "179             avf6   31.645255\n",
      "199            avf78   30.259596\n",
      "172            avf53   30.218690\n",
      "146             avf3   29.632619\n",
      "522        disney_ta   27.233223\n",
      "205            avf83   27.196010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [  27   81   87   91   98  122  148  149  223  225  234  242  245  252\n",
      "  265  273  277  300  308  314  318  319  320  324  342  343  348  350\n",
      "  353  357  358  364  371  373  376  377  378  385  391  395  411  413\n",
      "  416  417  430  432  434  447  462  469  483  490  493  506  514  517\n",
      "  518  524  530  540  541  563  565  566  567  569  570  572  577  583\n",
      "  588  596  598  603  605  607  622  633  642  646  661  669  690  692\n",
      "  709  719  731  732  749  767  772  773  784  786  788  802  810  811\n",
      "  825  827  831  846  851  853  859  864  881  900  904  914  919  925\n",
      "  933  940  945  955  957  958  990  994 1001 1002 1004 1021 1036 1038\n",
      " 1040 1050 1051 1057 1058 1075 1077 1096 1102 1128 1133 1136 1144 1173\n",
      " 1179 1182 1190 1198 1205 1225 1236 1242 1268 1270 1278 1287 1295 1306\n",
      " 1316 1318 1320 1335 1336 1339 1348 1367 1378 1396 1406 1418 1428 1483\n",
      " 1484 1515 1518 1529 1556 1562 1570 1587 1588 1597 1613 1625 1629 1653\n",
      " 1654 1656 1670 1672 1677 1685 1687 1707 1722 1725 1739 1751 1755 1758\n",
      " 1759 1779 1788 1804 1810 1814 1818 1821 1826 1828 1837 1847 1851 1857\n",
      " 1864 1867 1871 1876 1880 1882 1886 1887 1888 1893 1894 1897 1904 1905\n",
      " 1906 1913 1918 1924 1928 1930 1931 1937 1954 1960 1973 1975 1979 1982\n",
      " 2056 2075 2084 2088 2152 2173 2190 2193 2195 2201 2212 2214 2216 2220] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\diego\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "#anova test\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func = f_classif, k = 2000)\n",
    "fit = bestfeatures.fit(X_train2, y_train)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X_train2.columns)\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs', 'Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(20, 'Score'))  #print 20 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestFeatures = featureScores.nlargest(200,'Score')\n",
    "X_train3 = X_train2[bestFeatures['Specs']]\n",
    "X_test3 = X_test2[bestFeatures['Specs']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - Logistic Regression Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "c = LogisticRegression(multi_class = 'multinomial', max_iter = 100000, solver = 'newton-cg') # class_weight = 'balanced', solver = 'newton-cg'\n",
    "c.fit(X_train3, y_train)\n",
    "y_pred_LR = c.predict(X_test3)\n",
    "\n",
    "movieId = testFeat['movieId'].to_numpy()\n",
    "kaggle = pd.DataFrame(data = [movieId, y_pred_LR]).T\n",
    "kaggle.to_csv('kaggle992038_LR.csv', header = ['movieId', 'genres'], index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - XGBoost Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "c = XGBClassifier(learning_rate = 0.01, n_estimators = 1000, max_depth = 3, subsample = 0.8, colsample_bytree = 1, gamma = 1)\n",
    "c.fit(X_train3, y_train)\n",
    "y_pred_XGB = c.predict(X_test3)\n",
    "\n",
    "movieId = testFeat['movieId'].to_numpy()\n",
    "kaggle = pd.DataFrame(data = [movieId, y_pred_XGB]).T\n",
    "kaggle.to_csv('kaggle992038_XGB.csv', header = ['movieId', 'genres'], index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
